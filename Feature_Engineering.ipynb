{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPgPsNuK6jpq"
      },
      "outputs": [],
      "source": [
        "1. What is a parameter?\n",
        "Ans - A parameter is like a placeholder in a function that allows you to send values into that function so it can work with them."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. A.  What is correlation?\n",
        "Ans - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        " B. What does negative correlation mean?\n",
        " Ans - Negative correlation means that as one variable increases, the other decreases, and vice versa. The two variables move in opposite directions\n"
      ],
      "metadata": {
        "id": "amgNjLmO69MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "Ans - Machine Learning (ML) is a branch of artificial intelligence (AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed for every task.\n",
        "In simple terms, ML systems improve their performance automatically through experience.\n",
        "Main Components of Machine Learning:\n",
        "* Data\n",
        "* Model (Algorithm)\n",
        "* Training\n",
        "* Labels\n",
        "* Optimization Algorithm\n",
        "* Evaluation\n",
        "* Testing / Validation Data\n"
      ],
      "metadata": {
        "id": "vEUOt4md7e0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  How does loss value help in determining whether the model is good or not?\n",
        "Ans - The loss value (also called cost) is a numerical measure of how far off a machine learning model’s predictions are from the actual (true) values. It helps determine whether a model is learning correctly and improving over time."
      ],
      "metadata": {
        "id": "8raXLQKR8KDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "Ans - 1. Continuous Variables:\n",
        "Definition:\n",
        "            Variables that can take any numerical value within a range, including decimals and fractions.\n",
        "\n",
        "  Characteristics:\n",
        "  * Measurable, not countable\n",
        "  * Infinite possible values\n",
        "  * Often involve units like weight, height, time, temperature, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "c_bmy9xz8U4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "Ans - Machine learning algorithms typically work with numerical data, so categorical variables must be converted into numerical form before they can be used for modeling.\n",
        " Common Techniques to Handle Categorical Variables:\n",
        " 1. Label Encoding\n",
        " 2. One-Hot Encoding\n",
        " 3. Ordinal Encoding\n",
        " 4. Binary Encoding\n",
        " 5. Frequency / Count Encoding\n",
        " 6. Target Encoding (Mean Encoding)\n"
      ],
      "metadata": {
        "id": "yLbYXGj38tni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "Ans - In machine learning, a dataset is typically divided into two parts: training data and testing data. This division is essential to build a model that can learn from past data and also predict accurately on new, unseen data.\n",
        "1. Training Dataset\n",
        "* The training dataset is the subset of the original dataset used to train the machine learning model.\n",
        "* It contains input features (X) and corresponding output labels (Y).\n",
        "* During training, the model analyzes this data to learn patterns, trends, and relationships.\n",
        "2. Testing Dataset\n",
        "* The testing dataset is a separate subset of the original dataset that is not shown to the model during training.\n",
        "* It is used to evaluate the model’s performance and generalization ability.\n",
        "* The testing data also includes input features and known outputs, but the model predicts the outputs without having seen this data before."
      ],
      "metadata": {
        "id": "vBGi3IW09SHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "Ans  - sklearn.preprocessing is a module in the scikit-learn library (a popular machine learning library in Python) that provides tools and functions to transform and scale data before feeding it into machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "zgR4m9ha-AGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "Ans - A Test set (or testing dataset) is a subset of data that is separated from the original dataset and is used only after the machine learning model has been trained."
      ],
      "metadata": {
        "id": "hEPYJQZS-K5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. A -  How do we split data for model fitting (training and testing) in Python?\n",
        "Ans - When building a machine learning model, it’s important to evaluate how well the model performs on data it has never seen before. To do this, the original dataset is typically divided into two separate parts:\n",
        "  1. Training Set:\n",
        "* This subset of the data is used to train or fit the machine learning model.\n",
        "* The model learns patterns, relationships, and structures from this data by adjusting its parameters.\n",
        "  2. Testing Set:\n",
        "* This subset is kept separate and unseen during training.\n",
        "* It is used to evaluate the model’s performance on new, unseen examples to test how well it generalizes beyond the training data.\n",
        "B -  How do you approach a Machine Learning problem?\n",
        "Ans - 1. Understand the Problem\n",
        "* Clearly define the objective: What do you want the model to predict or classify?\n",
        "* Identify the type of problem: classification, regression, clustering\n",
        "      2.Collect and Explore Data\n",
        "* Gather relevant data from available sources.\n",
        "* Explore the data using statistical summaries and visualization.\n",
        "      3. Prepare the Data\n",
        "* Clean the data: Handle missing values, correct errors.\n",
        "* Feature engineering: Create new features or transform existing ones.\n",
        "      4. Split the Data\n",
        "* Divide data into training and testing sets (commonly 70:30 or 80:20).\n",
        "* Optionally create a validation set or use cross-validation for hyperparameter tuning.\n",
        "      5. Evaluate the Model\n",
        "* Test the model on the test data.\n",
        "* Use suitable evaluation metrics (accuracy, precision, recall, RMSE, etc.).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h8dFAgu7-Toz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "Ans - Performing Exploratory Data Analysis (EDA) before fitting a machine learning model is crucial because it helps you understand your data deeply and prepare it for effective modeling.\n",
        " * Understand Data Distribution and Patterns\n",
        " * Detect and Handle Missing Values\n",
        " * Identify Outliers and Anomalies\n",
        " * Feature Understanding and Selection\n",
        " * Choose the Right Model and Techniques\n",
        " * Inform Data Transformation Needs\n",
        "\n"
      ],
      "metadata": {
        "id": "T-OOezS7_-0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you find correlation between variables in Python?\n",
        "Ans - In Python, correlation is typically computed using the pandas library, which provides a convenient method .corr() to calculate the correlation matrix for numerical variables in a dataset.\n",
        "* The .corr() method calculates the Pearson correlation coefficient by default.\n",
        "* It can be used on an entire DataFrame to get pairwise correlations between all numerical variables."
      ],
      "metadata": {
        "id": "NqBXXf-oAhLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13  What is causation? Explain difference between correlation and causation with an example.\n",
        "Ans - Causation means that one event or variable directly causes another to happen. In other words, changes in one variable bring about changes in another variable.\n",
        "* Correlation shows a relationship but does not imply that one variable causes the other.\n",
        "* Causation means one variable directly influences the other.\n",
        "\n"
      ],
      "metadata": {
        "id": "isyuWJ9GA4xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "Ans - An optimizer is an algorithm or method used to adjust the parameters (like weights and biases) of a machine learning model during training to minimize the loss function (error). The goal is to find the best set of parameters that make the model predictions as close as possible to the actual outputs.\n",
        "\n",
        "Common Types of Optimizers\n",
        "1. Gradient Descent (GD)\n",
        "2. Momentum\n",
        "3. Adagrad (Adaptive Gradient Algorithm)\n",
        "4. RMSprop\n",
        "5. Adam (Adaptive Moment Estimation)\n"
      ],
      "metadata": {
        "id": "9BA9yZCaBPXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What does model.fit() do? What arguments must be given?\n",
        "Ans - model.fit() is a method used to train a machine learning model on a given dataset.When you call fit(), the model learns from the training data by adjusting its internal parameters (weights, biases, etc.) to minimize the loss function.This process is called model fitting or training.\n",
        "The exact arguments depend on the framework or library you are using\n",
        "* Training Data (Features)\n",
        "* Training Labels (Targets)\n"
      ],
      "metadata": {
        "id": "dVL8tVOlBzKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What does model.predict() do? What arguments must be given?\n",
        "Ans -  The model.predict() method is used to make predictions using a trained machine learning model.\n",
        "After the model is trained (using fit()), you pass new input data to predict() to get the model’s predicted outputs.Essentially, it applies the learned patterns to new or unseen data.\n",
        "* The main argument is the input data/features (X or similar), which should be in the same format as the training data.\n",
        "* The input data can be a single example or a batch of examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "NyTEWLOOCbOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is feature scaling? How does it help in Machine Learning?\n",
        "Ans - Feature scaling is the process of normalizing or standardizing the range of independent variables (features) in your data.\n",
        "It ensures that all features contribute equally to the model training by bringing them to a similar scale.\n",
        "Common methods include:\n",
        "* Normalization (Min-Max Scaling): Scales features to a fixed range, usually [0, 1].\n",
        "* Standardization (Z-score Scaling): Centers features around mean 0 with standard deviation 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IN1-CHzgCy6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. How do we perform scaling in Python?\n",
        "Ans - In Python, feature scaling is commonly performed using preprocessing utilities available in libraries like scikit-learn (sklearn). These utilities provide ready-to-use classes and functions to scale data efficiently.\n",
        "Common Steps to Perform Scaling in Python:\n",
        "* Import the scaler class\n",
        "* Create a scaler object\n",
        "* Fit the scaler on training data\n",
        "* Transform the data\n",
        "* Apply the same scaler to test/new data\n",
        "\n"
      ],
      "metadata": {
        "id": "mZgWOntaDR2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Explain data encoding?\n",
        "Ans - Data encoding is the process of transforming categorical (non-numeric) data into a numeric format that machine learning algorithms can understand and process.\n",
        "Many ML algorithms require numerical input, so categorical variables (like “red,” “blue,” “green”) must be converted into numbers.\n",
        "Encoding helps convert qualitative data into quantitative data.\n"
      ],
      "metadata": {
        "id": "GC1__-q_DqHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  What is sklearn.linear_model ?\n",
        "Ans - sklearn.linear_model is a module in the scikit-learn library that provides various linear models for regression and classification tasks.\n",
        "* It contains implementations of algorithms that model the relationship between input features and a target variable as a linear combination of the inputs.\n",
        "* These models assume that the target is a linear function of the input features, often with some noise.\n",
        "* Linear models are widely used due to their simplicity, interpretability, and efficiency."
      ],
      "metadata": {
        "id": "bjf5nHYrD-Qb"
      }
    }
  ]
}